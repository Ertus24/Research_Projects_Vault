I'm listening to episode 234 of Lex Friedman's podcast, because it's about complexity, and
I'm trying to unravel complexity a bit more, considering it's the basis of my whole fucking
argument.
And this one is, he's interviewing Stephen Wolfram, who I think is actually the guy who
founded Complexity Science.
And he's talking, Steve Wolfram's talking about how he became interested in complexity, because
it arises consistently in nature.
And he was asking, back in the '80s and '70s and '80s, he was asking, why does these complex,
complicated forms seem to naturally arise in nature?
But when we engineer things, they don't have that same level of complexity.
They tend to be straight lines and circles and stuff.
He said he tried to use mathematical physics to explore that, and he said it didn't work
very well.
That's what I've just gotten up to.
So I think, Steve Wolfram's probably a very good person to listen to, to read into about
complexity.
He talks about how do you model that complexity in nature?
And he explains what that model is.
He says it's an abstract, formal representation of something.
They would like to hear more about what formal actually means.
I get the sense that it means to make something very precise and clear, and to clearly delineate
the edges of something, to make it fit, to make it workable for analysis.
But to do that, you need to basically put it in a box, essentially.
It's about how he started building this model, because he basically had come from doing some
programming stuff, so he thought he'd tried that.
He talks about starting with computational primitives and building up from there and
seeing where it got from, which seems to be very related to this symbolic AI, go-fi stuff,
rationalist, all that stuff.
If we're going to use programs to model what happens in nature, what kind of programs do
we use?
I think this is actually the guy who made the game of life.
He talks about what kind of program we're going to use.
We're used to these big, long, complicated sets of code that are created to perform something
of a particular function, but if instead of that we just start with the absolute basic,
like really, really basic.
He talks about cellular automata, which is like a square that is black or white, and
its color is determined by its neighbors and its previous color, or something like that.
I think that's what he's basically getting at in terms of computational primitives.
That sounds exactly like the game of life.
I think that's exactly what this is going to be, basically.
What he was working with was a line, like a strip, basically, and the color of a cell
was dependent on its previous color and its two neighbors, so the one on either side of
it.
He thought that that was simple enough that nothing really interesting would happen, and
I'm guessing that led to emergent properties, which then, I'm guessing, probably led to
the game of life.
With this most minimal, simplest programming thing, simplest, most minimal program, you
can get very complicated behavior.
I don't think he's probably going to lay out some examples.
He realized that that's probably how nature does it, even when you have this really simple
program when you actually run it.
The behavior isn't simple at all.
He gives a definite...
The original question that Lex asked him is, "What is complexity?"
He says, "The informal definition is something where it's not easy to tell what's going
on."
He talked about how rules can generate randomness.
Well, actually, Lex raises this, that rules can generate randomness.
He's like, "Wolfrums, that wasn't obvious at all.
You think if it's a rule, it's going to be clear."
This is making me think that maybe complexity is not quite actually what I'm going for.
Maybe it's actually something greater than complexity is.
I don't know.
Maybe something more than complexity is what's going on, because it's more than just it's
hard to tell what's going on.
He basically says, "People assume that simple rules mean simple behavior, but that isn't
necessarily the case at all."
Which to me sounds like an example of engineering patterns, simplifying, butting up against
the complexity of nature.
As Wolfram says, the key discovery from all of this was that this assumption that simple
rules mean behavior and simple outcomes is not actually true.
You can have very simple things and still get very complicated outcomes.
That was the key discovery.
That goes really deep and is present in many, many things.
He spent his lifetime looking into that, basically.
He basically says complexity is like you can't easily tell what a thing is going to do, what
a rule is going to do.
That's complexity, which feels like not enough for what I'm trying to get at.
I wonder if there's a philosophy of complexity that doesn't do things in necessarily this
analytical, methodical, mathematical, precise way.
He says the outcome of that, of the fact that you can't just ... That complexity means you
can't just work out what's going to happen.
You can't just give somebody a simple rule and be like, "Well, okay, I know what's going
to happen."
He says the outcome of that is what he calls computational irreducibility.
It's basically like, "What is this simple rule going to do after a million steps?"
The idea of computational irreducibility is you actually have to run those million steps
to work to find out what's going to happen.
You can't just have that set of that rule and then know what's going to happen.
He says you can't ... You could run those million steps and see what actually happens,
but you can't actually compress that.
You need to actually run it to see what's going to happen because we can't predict from
the ... We can't predict from the ... We can't predict from the simple rule what
the outcome is going to be.
All of this, this is just another example.
This is like convergent evidence.
It's another example of this phenomenon I'm trying to get at, but all of these things
kind of seem to be dancing around the actual thing.
I'm not quite sure what point of it is that he says this, but he says people have this
idea that we've nailed everything down with science.
We ... What does he say?
Give me a moment.
He says, "Based on ... People have this idea of ... Maybe not everybody, but people who
... There are people who say, "Based on science, we can know everything."
He's like, "Well, actually, science itself has thrown up this computational irreducibility
that we can't know exactly what's going to happen without actually running the fucking
program."
He says, "If that is the case, if it is the case that ... Because of this computational
irreducibility, we can't know how things are going to be, how is it the case that we can
predict anything, how can we operate in the world?"
He's about to give an answer.
He talks about how ... The reason for that might be ... It seems to him quite likely
based on his evidence and his models and his work that we exist in a sea of computational
irreducibility, but there are slices of computational reducibility that occur and that are relevant
to us.
He's drawing on a powerful model of physics that's applicable to other things as well
that he's developed.
I think that's a fucking fascinating idea.
I think that also in some ways maybe aligns with my whole argument that the universe is
infinitely complex, but we engage constantly in the process of simplifying and framing
it and that does actually work and that's okay.
We can trust that for the most part, but it doesn't mean we'll ever find a final answer.
This is about 27 minutes in.
He starts talking about this.
He says, "Yeah, these slices of computational reducibility that we exist in that are relevant
to us are what allow us to predict, have the world be somewhat predictable."
Just pattern.
Hold on.
"But they are also what gives us what might amount to physics-like laws."
He's written a book that Lex is referring to.
In that book, he references, he talks about islands of reducibility within a sea of irreducibility.
That sounds very fucking interesting and really apt and relevant here, I think, that I should
maybe have a look at.
He says something interesting is that apparently, there's a lot more context here, but apparently
he says that the computational irreducibility is what leads to the second law of thermodynamics,
which I think is entropy.
His whole idea is that, starting with basically in physics, starting with the idea of what
is space and rather than the traditional idea of space is just a void, space is space literally.
It's a nothingness that you can just have other things in.
His idea is that space is made of something.
Space is composed of space atoms or space somethings.
We don't know what they are.
We don't really know anything about them other than the fact that they are related to each
other and that everything that we know of and we experience, atoms and all of that shit,
is actually basically an outcome of the behaviour of these networked space things, particles,
atoms, whatever.
They briefly talk about levels of abstraction and how if you zoom out enough at every level,
there is an entity there that you can define.
But from his saying, at the bottom level, there is, in this model that he's working
with, he's creating, he's working with, there is a bottom level basically and it's this
space stuff.
