Again, still listening to episode 27 of Awakening from the Meaning Crisis, so where he's talking
about algorithms and heuristics and stuff, and this is him getting into critiquing Newell
and Simon and their work on the general problem solver, and he's talking about how they thought
that all problems, they succumbed to the centralism heuristic and assumed that all problems are
basically the same, which means that if that's the case, you only need one problem-solving
solution to be able to solve all problems.
And they had mechanised and formalised this and turned it into a series of steps, and
I imagine that meant that they were then just, if you do these things, you'll be able to
solve any problem.
And that's exactly, that's in some ways what a lot of logical positivism and that's what
a lot of science has looked for.
It's looked for predictable, repeatable underlying patterns that you can use to then solve any
class of problems without having to interpret.
It's looking for objectivity so you don't have to interpret, you don't have to deal
with the complexity of the world, because you just have a ready-made solution.
It's a bit of an oversimplification, but I feel like there's some truth to it, and that's
an important point.
Science is in some ways us trying to battle against the complexity of the world, the combinatorially
explosive nature of existence.
And he's going on to talk about the difference between how they didn't realise that there's
well-defined and ill-defined problems, and I think that they assume that most problems
are well-defined problems, which means that you can follow this set of steps, which I
think is actually something that a lot of logicians and people in that rationalist space
have done.
They have assumed that...
I mean that's basically what a comment...
When you go to university, you get well-defined problems.
You're given well-defined problems.
When you...
A lot of the ways we could learn, we're given well-defined problems.
A lot of the ways that... and I think logicians and stuff trying to apply...
Like economists, they kind of deal with well-defined problems, or they...
Well, actually, no, they don't.
But they assume things are well-defined problems.
Logicians often apply things, take things from somewhere where it is a well-defined
problem, like games, and take that and try to apply it to ill-defined problems like the
real world.
That's something that happens a lot.
He also talks about how, like I noted, education is kind of about training us to turn things
into... either training us on...
I'm not quite sure what he means.
I'm not sure if...
It's either training us on well-defined problems or training us to turn things into well-defined
problems, basically, probably by training us on them.
And he also talks about... then mentions that a lot of what psychotechnologies do is turn
things into well-defined problems for us, which is important, which is interesting because
that links, I think, to what David Chapman talks about in his stuff in the Cell... in
the Cell's of the Eggplant blog about how rationalism and rationality works in practice,
that it takes work and, in some cases, engineering.
We have to engineer the world to be... to more match the features that we assume to
be the case in our rationality so that our rationality will actually work, i.e. we use
psychotechnologies to turn things into well-defined problems, but the universe is... but existence
is an endlessly ill-defined problem.
So we force things into certain shapes and certain... make certain assumptions, force
things into certain shapes, force things into... we make things into well-defined problems
so that we can consistently solve those problems.
And that's a lot of... that's what a lot of technological progress has been, turning things
into well-defined problems with, you know, known solutions, well-defined problems with
known and easy solutions.
We know how to do this, we know how to do this in pretty much every instance, we're
going to keep... you know, we know when this happens we do that.
Or, you know, changing the world so that things are more well-defined and easier.
And that's also what that book, and in some ways what Desystemize talks about, what the
Substack Desystemize and what that book are seeing like a state talk about, where part
of what... the way that a state functions, or maybe what is necessary for a state to
function is to make things more well... like force things to be more well-defined, you
know, with censuses and measurement and all that kind of stuff, you know, it takes the
messy reality of things and shaves off some of the complexity, I guess.
It shaves off some of the complexity and makes things... and forces things into a more well-defined
state so that it can measure it and keep track of things.
But in the process, and that's important because then we get all the benefits we get of states
and capitalism and all that kind of stuff, you know, where things are efficient and they
work and all that kind of stuff.
That's actually a lot of what capitalism does... capitalism and the modern nation state and
what civilization does, it's shaving off that complexity.
Shaving it into a simplified, well-defined state.
However, in doing that, things get... other things get shaved off.
Things fall between the cracks.
People who don't quite fit into those categories or ways that the world are that don't quite
fit or, you know, the complexity of the world sometimes gets overlooked in bad ways, basically.
Importantly, you know, like important stuff gets missed which can affect people's lives
dramatically.
And fuck, this is like a... this is stuff, something I want to write about so much.
I want to build out from what I want to get to here from where I'm starting, from my manifesto.
He specifically uses the examples of literacy, numeracy and mathematics as examples of psychotechnologies
that we use in order to make things into well-defined problems for us.
Which is kind of in some ways connects to what Wittgenstein says, that we're stuck in
language.
We can never see... we can never get outside of language.
But language is a psychotechnology that makes things in some ways more well-defined.
It locks the bubbling complexity, the chaotic complexity of the world down, which is good
and useful and important, because it means we can fucking communicate at all, but it
also means things get shaved off.
Necessarily.
Like, no matter how deep you go, there's always another level of complexity that where things
are getting... through the tools we use to understand the world, some element of reality
is not captured within that tool and is lost.
Again and again and again, always, and no matter what you do and no matter how deep
you go.
And we have to constantly refine our tools and push back against that, because not only
is that the only way to progress, but it's also we need to adapt, because existence is
also constantly changing.
God damn.
God this stuff is also interesting.
It's like... it makes my brain sing.
And seeing the connections between John Viveci and David Chapman is just such a fucking...
I don't know how to explain it.
It's such a rush.
It feels...
This is probably sometimes, in some ways, not for the best, but in some ways it feels
like I'm singing deeper into reality.
And Johnny V also talks about how... he mentions that these psychotechnologies we use, like
literacy and numeracy, etc., are... because they are so powerful and because we use them
so much in our education, because we gain so much experience with them in our education,
we then assume that that's what most problems are like, what most problems should be like
or naturally are like.
They are well defined.
But they're only like that because we are consistently able to... we are taught to consistently
apply those psychotechnologies and thus make ill-defined problems into well-defined problems
through the work of... through the work that previous generations have done in creating
and applying and adapting those psychotechnologies.
Our lives are made easier because we are able to apply it to simplify things.
And all of that means that because we are... because most problems that we interact with
are well defined already... because of the tools we use are already well defined for
us, because of the psychotechnologies, it means we don't have to pay attention to the
way in which we formulate those problems, which means that then when we're confronted
with ill-defined problems, we're not prepared for them or we don't pay attention to what
we do to make them into ill-defined problems.
And I think that's in some ways what links a bit to what David Chapman talks about with
metarationality, how people who are metarational seem to just have this magical ability to
come in and fix things and see things that nobody else could.
Because I imagine they are able to... in some ways maybe they are able to see problem formulation.
And then he goes on to... 44 minutes goes on to talk about... this is what he says, "What
is missing in an ill-defined problem..."
Give me a sec, I've got to check it again.
"What's missing in an ill-defined problem is how to formulate the problem, how to zero
in on the..."
Right, this is what he says, "What's missing in an ill-defined problem is how to..."
Fuck.
"What's missing in an ill-defined problem is how to formulate the problem, how to zero
in on the relevant information and therefore constrain the problem."
That's what our psychotechnologies that create well-defined problems are doing for us.
They are allowing us to focus on the relevant information.
They're doing relevance realisation.
They are constraining the complexity of the world so that we can focus our attention on
what's relevant to solving the problem.
They basically do relevance... they do relevance realisation for us.
Wow.
Okay.
Fuck.
That's really interesting.
Psychotechnologies, a lot of psychotechnologies, turn ill-defined problems into well-defined
problems by formulating the problem in such a way that it constrains it and allows us
to focus our... to zero in on and focus on the relevant information, which means that
our psychotechnologies are taking ill-defined problems, doing relevance realisation for
us so that we don't have to, and then turning those problems into well-defined problems
so that we can interact with a more simplified version of the world.
Fuck.
That is really interesting.
And this is kind of just saying the same thing, but it's kind of, I guess, expanding
on it slightly.
So essentially what psychotechnologies that turn things into well-defined problems do
is they avoid combinatorial explosion.
And it would make sense that people aren't aware of combinatorial explosion because the
way we are taught, the way we are raised, and the tools that we are given to think about
the world, the way we are taught to think about the world is through well-defined problems,
psychotechnologies and well-defined problems that are handed to us so that we don't have
to interact with ill-defined problems as much or in the same way.
Despite the fact that what he... although having said that, he also says, and it is
clear that most of our problems are still ill-defined problems.
How do you tell a joke, go on a good first date, have a conversation, all of those things?
It's like, what exactly are you supposed... what do you do exactly?
And it's learn the skill of relevance realisation in that particular context.
I've also just realised he's had the end of the... from about 47 minutes on, he talks
about the mutilated chessboard... yeah, he talks about the mutilated chessboard problem
and... this has to do with problem formulation, stuff like that.
It reminds me of what David Chapman talks about with the... I think they're called Bognard
problems or something like... something-nard problems, which are what he uses as an example
of being meta-rational, like solving those is an example of being meta-rational.
I'd have to check both of them and really pay attention to both of them, but they...
mutilated chessboard reminds me of that, which maybe means there's a link here from what
John Bavay is talking about to David Chapman's meta-rationality.
Yes, it's the same thing as the nine-dot problem.
So basically he says it's really hard for a lot of people because they frame it, they
formulate it, the problem, as a covering problem where you have to cover the missed... you
have a chessboard, how many dominoes do you need to cover all of the pieces of the chessboard
with no overhang, it's 32 because each takes up two spaces, etc. etc.
And it's... when you show those people that initial thing and then do this other... and
then change it to the mutilated chessboard, people get stuck on it being... this being
a covering problem where they have to solve the problem by covering it.
They're framing it in a certain way where they have to use... they use a certain set
of tools and a certain way of thinking about it, formulate the problem in a certain way
to solve it.
But what they have to do is break... is get an insight and break out of that framing of
the problem and frame it a different way, formulate the problem a different way, focus
their attention on a different relevant set of properties and features in order to solve
the problem.
And that sounds a lot like those Bognab problems where it's like you have to look outside of
the... you have to look outside of the... you have to look outside of the frame of the
systems you are used to using to solve the problem.
Which sounds like meta-rationality.
Meta-rationality is... in some ways sounds like insight.
It's like being able to utilise the tools of a system but not getting locked into, not
always formulating every problem through the lens of a certain system like differential
equations or mathematics or whatever.
It's about recognising how to... when and where and how and why to use different systems
in different contexts and how to change them and what's the problem with them and breaking
out of the frame that a system gives you.
A system, a systematic way of thinking, a systematised, a formalised system like programming or coding
or mathematics or various... all the various sub-features, sub-junctions of each of those,
all of that, each of those is a way of... it's a way of formulating problems.
It's a way of turning problems into... it's a psychotechnology that is a way of turning
problems into well-defined problems.
Right?
And meta-rationality is about being able to navigate, to break the frame, being able to
break the frame when you need to, to not get locked into the frame that is provided for
you by that system.
It's being able to break out of the problem formulation given to you by a certain system
so that you can use a more appropriate system or develop a new one entirely.
That like... such a fucking strong connection there.
I am seeing it so heavily.
I really want to write about this so bad.
Then he goes on to talk about how one participant who was trained in mathematics in the experiment
that Simon and Ackerman or something like that...
I can't remember what their name is.
Yeah, then he goes on to talk about how towards the end of the episode he talks about how
there was, in this experiment that Simon and somebody did, Choney Ack maybe, in 1990 where
they basically did the... they gave the mutilated chessboard problem to a bunch of people.
One of the participants was a... was trained in mathematics and they... and they tried
to work out by hand through a mathematical equation.
They tried to work out, doing a geographical topographical calculation or something like
that, tried to work out what the answer was and they spent 18 hours, straight hours, and
wrote 84 pages of calculations and didn't find an answer.
And the reason is because it's a combinatorially explosive problem and they're framing it in
the wrong way.
And he says it's exactly... it's actually exactly because of these people's... this
person's prior framing, because they are a mathematician, they are going to... they will
bring their... it's exactly because of their use of that psychotechnology, their training
in the use of that psychotechnology, that they will become locked into that problem
formulation.
They're trained in mathematics, they're going to... it seems like it's them to their relevance
realisation mechanism.
It seems like a mathematics problem because they're a mathematician.
They're going to do mathematics to try and solve the problem and precisely because of
that they're going to get locked into a combinatorially explosive formulation of the problem, which
is exactly what metarationality is.
That's exactly how metarational... that's exactly what happens with rationality and where people
get stuck with rationality and where metarationality moves beyond it.
Rational systems are extremely powerful.
Rational systems are extremely, extremely powerful for solving problems, for condensing,
interpreting, for turning... will define problems into will define problems, which is absolutely
necessary.
They are so incredibly powerful.
That's why we have all of these things.
But they are constantly going to butt up against the ill-defined complexity of existence, which
means that they constantly need to be updated, they constantly need to be monitored, and
you need to be aware of when to use them and when not to, which is why people who get hyper-specialised
into one field can't escape.
They get very, very good at doing one particular... using one set of tools.
They get locked into a system.
They get very, very good at using that system, but they can't see outside of that system,
and no one system will ever be able to have all the answers.
So one system... every system will always... there will always be parts of the complexity
of existence that will fall outside of any system, which means that any system is always
going to cut those bits of complexity off, which sometimes is okay and necessary, but
also means sometimes it's not going to work.
That system won't work to solve some problem that you think it's going to.
Or the parts, you know, those bits that get cut off may affect somebody because you're
not aware of the ways in which they inhabit that space, that liminal extra space that
you sliced off with your rational system.
Right?
And our society has become hyper-obsessed with a particular set of rational systems,
to the exclusion of everything else, and they use it in too many contexts where they should
necessarily be used, and they become rigid and unable to adapt them.
And also, I hope any of this is audible over the fucking cars.
Jesus Christ, it's so loud.
Hopefully the wind thing gets rid of it, but yeah.
There was a thought there related to David Chapman.
Fuck, what was it?
I think that was maybe the other thing he was talking about.
It was that David Chapman talks about that kind of relates to this.
It's...
Ah, no, it's going again.
I'm losing it.
Fuck, what was it?
Um, that...
Yeah, I think that was it.
It's that.
It's what David Chapman talks about of no one rational system will ever be able to...
Do everything.
Will never be able to have every answer.
That's exactly what he was talking about, where people get locked into an ideology or
a rational system or a religion...
A system.
They get locked into a system.
And they assume that...
They assume that...
They assume that...
Sorry, I just got distracted by dogs.
They assume that, um, you know, that that rational system didn't have the answers, but
that there must be some answer out there.
There must be some rational system that has all of the answers.
That we just need to make our rational system better.
It's not always rational system.
We just need to make our system better.
We just need to fit...
You know, that's what he talks about with the responses to uncertainty and rationalism.
Just trying to bolt on all these extra things to try and solve the problem.
Whereas the problem is actually unsolvable.
And the answer is to not to jump from one... not to improve a system or jump from one to
the next.
It's to hold multiple and learn how to balance them all.
I quite, quite remember now how this relates to what John Vivecki was talking about, but
it's definitely there.
There's definitely a relationship.
So exciting.
I really want to write an article about this.
About the relationship between David Chapman and John Vivecki's work and metarationality
and what John Vivecki talks about and just all of that stuff.
Oh, god damn.
I want to do this.
I want to work from my manifesto to outwards to, you know, not proofs but evidence for
why I think these certain things, why I think each of these ways, why I think of the duality
and then the opposition of forces and the complexity and all that kind of stuff.
Each of these elements.
Provide evidence for each even if they're each in their own separate article.
And then from there build out to what the outcome of that is.
Like the ethical outcomes.
Like being more empathetic towards people.
And also the, but then also go from there to then synthesise other things like John
Vivecki and David Chapman's work.
And I am so fucking excited by all of this.
It feels like I'm finally getting somewhere.
I haven't really started.
I've done the very, very, very, very, very first step and it's an enormous amount of
work to come and I'm suddenly very glad that I'm only working three days a week because
suddenly I want to spend at least one whole fucking day every week doing this.
Walking around getting my ideas out, condensing them down, doing all of this shit basically.
I might actually just be sticking to doing three days a week for a while.
Because if I really stop to think about it, this is probably, I probably care about this
more than I care about making and saving money.
This is like what I want to do with my life.
I think I would be quite happy working three days a week, staying at Mum and Dad's, working
three days a week for the next year and spending a day or two every week, a whole day or two
every week focusing on this.
Just pouring myself into this.
I would fucking love that, I think.
What a way to live.
Now if I could just do that outside of house, like outside of Mum and Dad's, find a way
to do that outside of Mum and Dad's house in the UK with all my friends around, fucking
perfect.
That would be the perfect life.
So yeah, maybe four days won't be happening after all.
We'll see.
We'll see what happens with this and where it goes.
I need to actually do it first before I jump any guns.
Darken bugs in my eyes, god damn it.
Also I feel so much relief at being able to just focus on this.
I didn't realise how much of a cage Holly's expectations felt like.
How much of a cage Holly's expectations felt like.
The idea that I don't have to fucking worry about what she wants me to reveal, what she
needs from me.
I can just pour myself into the thing I love and am passionate about.
That's so freeing and also probably a sign that things maybe weren't actually that...
Ways in which I was struggling with things in our relationship that I didn't notice.
And that I'm not going to...
I probably shouldn't, except I should probably be with somebody who is okay for me, who wants
me to be me, loves me for me and doesn't need me to throw my...
It's not what she needed, she didn't want me to throw my passions aside.
But it's an interaction between me and her as well.
I turn her thing into a larger expectation of myself to eternalise and make into a problem
for me.
And it stops consuming my attention.
As tends to be the case.
So it's not all on her.
But I don't want to do that again.
Also it really feels like there's acceleration or something with thinking and insight points
and doing what I'm doing at the moment.
It feels like once I get started it's easier to keep going.
It's like that starting is really fucking hard.
But once I get started it's easier.
It's like it has its own momentum.
There's like a shitload of friction to begin with.
And then once I overcome that it just kind of keeps building momentum and connection
points just kind of keep coming at me.
