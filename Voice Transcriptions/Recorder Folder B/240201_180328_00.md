listening to episode 337 of the Lex Friedman podcast, Friedman, Friedman, at about 39 minutes.
This is at the episode talking to Destiny. This is 39 minutes in and they're talking
about AI and Lex is talking about how, a couple minutes before that, they talked about how,
he didn't think Go was solvable, because we could only be brute-forced, there was no efficient
way to search, that it's a, most problems are giant travelling salesman problems, etc,
etc. And then he goes on to talk about how, that it's mind-boggling that AI is able to
do these things with representations, like things with art and words that seem like that's
the things that we should, that are solely our focus, that's the thing that we focus
on as being evidence of what makes us human. And yet, the thing that robotics actually
struggles with the most is the real world, like picking up a cup or moving. What we're
seeing there is vastly, is I think, I'm guessing, like not keeping pace with the rate of the
developments in things like language models and art and shit like that. And that's super
interesting to me because that's like, and we think it's pretty trivial to interact with
the real world, like pick up a cup, and what we think of as makes us us is doing art and
shit, but actually, the stuff that we think is trivial is the stuff that it struggles
with a lot more than the stuff we think of that makes us human. Doing math, doing art,
writing, etc, etc. And I think it's, the reason I think that might be the case is because
the art is operating, like the generative models are operating within a closed space. They're
operating within a very large, tiny world in the sense of the GoFi symbolic AI sense
of, they have these set parameters. It has a set of parameters within which it can operate.
It's a very large set of parameters. We've basically fed it the internet, which is an
enormous amount of information, but it is a set amount of information. We feed it enough
of that. Still, I'm not quite sure because it's not interacting. Is it interacting with
the real world, with reality? I'm not sure. Or is that just representations? Is that a
separate thing? But I think that's why it does better there than it does in the real
world because the real world is not a closed space. It is almost infinitely complex. And
because the number of variables that are potentially relevant to almost anything are almost infinite,
whereas maybe that's not the case in representations. And maybe that's not the case because we've
already made things relevant. We've already decided that things are relevant in language.
Language already has relevance baked into it. These words are relevant to each other and
thus they form sentences. That's why they occur together. And we have basically fed
it relevance realisation already so it doesn't have to do it itself. I think that might be
the case. We have basically spent several thousand years doing the work of relevance,
of realising relevance on a vast scale, done all of that work and then handed all of that
work to this ultra-powerful processing machine that can take all of that and spit and generate
shit because it doesn't have to focus on relevance. But I don't know. I don't know enough about
AI. Maybe AI is... I know that was definitely a part of the struggles of early symbolic
AI was you had to program the relevance into it. It couldn't know what was relevant. Yeah.
So I'd be interested to know what the interaction between AI and relevance. And I'd actually
be really interested in how robotics works in like the real... like applied robotics
in the real world in terms of movement and vision and picking things up and shit like
that. How? Because we can. We have gotten to a point somewhat. It's not incredible like
it is. I mean it is pretty amazing but it's not compared to what fucking symbolic AI,
like representational generative AI can do. Robotics is nowhere near that. It can't do
things that blow us... We have made things that can walk and it can pick things up. But
like how and where does it fall apart? Have we essentially programmed in a set of... you
have to do this thing and this thing and this thing and we've just... we have given it the
exact parameters and then it falls apart as soon as it encounters something that doesn't
fit those parameters because it doesn't know how to deal with it because it can't do relevance
realisation. Or have we worked out ways to do robotics in a way that robots can deal
with uncertainty and you know with novel situations and things like that. Has robotics gotten
to that point? Actually makes me quite interested in robotics to be honest. Even though that's
having much less of an applied impact in our world compared to AI, it is I think probably
philosophically vastly more interesting. A little bit later at 41 minutes he says that
we are really resilient and able to adapt to a really dynamic environment and that maybe
the only way to get that is to basically run the whole evolutionary process all over again
from start to finish and that maybe creating robots that can have that dynamic interaction
with the environment, dynamic resilience to a dynamic environment where they can interact
with it, this dynamic environment and not just fail and fall to pieces is really fucking
hard and that's exactly because of that reason that I was talking about I think. I think
in some ways realising relevance is central to our fucking, to our evolution. It may be
central to the evolution of life.
Thanks.
[Music]
