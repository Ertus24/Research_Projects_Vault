So I'm listening to a...
Listening to a...
David Chapman's latest podcast episode, which is on his sub stack.
On his Meaningless sub stack. It's called Lineage. It starts with Lineage, I can't really see what the
fucking rest of it is. Lineage and Learning with Max Langenkamp.
I don't know who that is, but it sounds like they're worth listening to because he mentions
John Vivecki and his four Ps. Three Ps? Four Ps. Four Ps. But they're basically going through...
So the beginning is really interesting because he's talking about his... The three lineages of
AI. Talking about Marvin Minsky, some other guy, and Simon and Newell, being the three lineages,
and his experience working with them. And talks about how his paper basically mathematically proved
that the research program of the lineage he was a part of at the time couldn't work
because of the frame problem, basically. Which was that the idea was basically to program in
all the knowledge necessary. Whereas apparently... I don't know, he doesn't really talk about Simon
and Newell other than saying it also wasn't going to work. But he talks about Marvin Minsky
as basically being kind of... Having more of a developmental psychology approach, and that
intelligence has to develop over time rather than, I think, the John Cambridge or something like that.
John something that was the lineage that needs, or something like that, which was the lineage,
the group that he learnt from. Well, apparently he ended up also learning from Marvin Minsky.
Their approach was to try and basically just program in all of the necessary knowledge.
And his whole, his PhD thesis was mathematically proving that due to the frame problem,
that's not doable. And he also mentions that NP completeness, which I think is part of the PNP,
as part of that. So I should probably read his PhD thesis at some point.
But, yeah, he's talking about different lineages and transmission of knowledge and stuff.
And they're not actually really talking about the lineage part of it all that much. They're kind of
more talking about the transmission and just lineages he's been part of rather than the existence
of lineages themselves. But he's talking about how he wants to teach. He talks about Charlie
Aubrey, his spouse, and the evolving ground that is part of the lineage of our gutter,
but it's starting to become its own thing. And that Charlie has this mentor relationship with
people that are really dedicated and close to it, which really makes me want to start doing some of
Charlie's evolving ground, getting involved in that. And at some point the guy who's interviewing him
or having a conversation with him raises John Vovecki's four Ps. And David Chapman doesn't
really talk about it too much, but he basically agrees with it somewhat. But then he talks about
how David talks about how he has wanted to basically teach in person, teach meta-rationality,
which is something I really want to be part of. So basically I think I want to make connections
with these two people, Charlie Aubrey and David Chapman. The guy's talking about Max
in his undergrad apparently learned about mixed effects models or something like that,
which sounds like statistics in psychology, because he mentions Fisher, who's I'm pretty
sure the guy who came up with the fucking P test. But yeah, they're talking about how the models
create. You have random effects and fixed effects, and then Max is like, "There are no fixed effects,"
because that's assuming that there are objective stuff. Basically the important part is David
Chapman saying when the foundations of this stuff was created, when the foundational work behind
this stuff was done, they didn't have computers. So they had to do massive simplifications in order
to be able to do the computations, because the computations had to be done by hand at that point.
Maybe calculated. They didn't have modeling software. They didn't have to compute digital
computers. The important thing he says is that the underlying assumptions
haven't been updated in those fields, haven't been particularly in statistics,
I think is what they're talking about, haven't been updated since the advent of digital technology
that would make it feasible to actually change those things. So the assumptions underlying all
of this stuff is still based on these massive simplifications and these ideas of what's objectively
true and stuff like that, which are really interesting. The Monte Carlo methods, which are
kind of like a very different... He says there's a very different approach to Fisher, which is
apparently massively multi-dimensional space and massive amounts of data. So I'm guessing that's...
The Monte Carlo method is where they actually start to bring in the... You start to challenge
those assumptions by bringing in the new powers of computation, of digital computation, compared to
the assumptions. Stuff that used to have to be done when it was like this. So this is...
So Max, after they continue the discussion a little bit more, Max says the experience of trying to
use these models and realising that it breaks things up into random and fixed effects and that
there are no fixed effects made him realise that there is an abj... His words are, I think,
"There's an abject lack of understanding about statistics and what they are used for among even
the most preeminent scientists." Which I fucking love. It's later in the afternoon now. I'm on my
way home, listening to it again. I'm up to about 29 minutes in and they're talking about the
replication crisis and the lack of understanding of... The fact that experimental psychologists
have a... Generally have a... There's a massive lack of understanding of statistics in experimental
psychology and that's an enormous problem. And I realised that that was what turned me over.
That was what in my... I got halfway through my honours year, honours program,
and realised... Looking back, I realised that that's the problem. That's what put me off.
The complete... And David Chapman talks about how there's a sense that the response to
the replication crisis is to teach more statistics more rigorously. And he says that might be the
case, but that misses the problem, which is the actual problem, which is that we need to teach
the meta-rational aspect of statistics of what are we actually trying to answer here
and is the methods we're using... Can it actually do that at all?
And I realised that that year... I think it was a combination of
them still not really talking about their replication crisis all that much, kind of just like,
"Oh, a little bit, a bit more than previously, but still not that much." I do remember one of
the statistic courses, they were like, "Throw out most of what you just learnt from your previous
studies," kind of thing. But yeah, it was the lack of really covering that. The fact that I'd kind
of like... And I think the essay I did on Bayesian stuff as well, where I did an essay on... I did
this, the class on Bayesian inference, and the feedback I got was just... I mean, I was probably
not really writing for what they were looking for, but it was just like completely missing the point
or something. Yeah, I don't know. It felt like that essay, that last essay I did about probability
and Bayesianism in psychology, like the new Bayesianism in psychology. And the response I
got on it... I don't think I did that essay particularly well. It was a confusing essay,
but I think my response to it probably... It definitely was not what they were looking for,
but else I don't think I did a great job. It was very rushed, et cetera, et cetera. But the kinds
of responses I got were just like... It felt like dogma, I think. The responses I got felt like
regurgitated dogma. There seemed to be very little talking about the replication crisis.
And between that and the seminar series I did where we were reading all of these papers
and they were talking about mental models and mental calculations, I'm like, "What? Mental coding?
I think neuronal coding." I was just like, "What the fuck are you people talking about?
What are the assumptions here?" Because there's no mention, there's no talking about, they don't
talk about the assumptions. And I tried to delve into it and work out what these assumptions were
and where they would follow the references back. And it was just like, "What is the basis for any
of this?" It was just so philosophically slapdash, so philosophically ignorant. So it was enraging to
read. And then doing my... I think I becoming interested in philosophy for a bit and getting
into John Vivecki really opened my eyes. It was like a confluence of getting into John Vivecki,
learning about that and David Chapman, learning about the replication crisis and then getting
to honours and being like reading through all these research papers in the seminar class and
just the bold assertions and absolute no questioning of assumptions. Just these ideas that just...
Things like neuronal... The very heavily computational theory of mind that just...
I'm struggling to put it into words, but just felt so... It felt wrong and it felt like dogma,
completely unquestioned dogma. The responses I got to my Bayesianism thing and then doing that
class and doing the internship where seeing that in practice application of this...
Seeing that in practice application of the behavioural... Basically my job was to troll through
literature and then present it. And it was like... We're not... We're just taking it face value
that all this literature is worth paying attention to. Like... Seeing that the capitalism of it in
behavioural science applied to... Capitalism applied to behavioural science. Like they don't
care. The people who are listening don't care. The people that's reported for don't care. They
just want to know the absolute barest information they need to keep making more money basically.
And they're trusting that we know what we're talking about. And we're not doing... Like we're not...
*sigh*
There was no question... It was just digest as much of this as possible and chuck it together.
Like there's no real critical assessment of any of this. It just made me completely disillusioned
with psychology. And that's why I haven't gone back to do my honours. That's why I haven't
gone back to finish my honours. And yeah it's actually really... It's a really,
really important thing to notice all of that. I don't know what the next step after that is,
but that's why I didn't finish my psychology.
Yeah. And I don't know if I can go back and do it... Do any more of it. I just... I don't know what to do next.
Into my first year of honours I couldn't take psychology seriously anymore basically.
Yeah. Part of why I care so much about David Chapman's work because it's like...
It is putting that into like practice. It's like directly, clearly pointing out those problems I
had and what actually the problem is. It's the lack of meta-rationality. It's the cargo cult science.
I just... I can't... I can't do that. I just can't fucking do that. I'm not the kind of person who
can just shut up, get paid to do nonsense. I just can't do it. And look, to be fair, just like both
of the stats... All the stats courses I did, they were okay at pointing out issues. Like they could
have been a lot better, but I think they were probably the best of all of the classes. All the
rest of the classes were just like meh. Like they didn't even question assumptions, but...
Particularly experimental psychology. Like all of that stuff I was reading
was experimental psychology. It was based on computational theory of mind and
like a poor understanding of statistics. I just couldn't take any of it seriously.
But the statistics classes, they were like... Sometimes you don't need the statistics. Sometimes
they were pushing away from P and talking about the importance of effect sizes. They were saying
sometimes... Which is something they've just said in this... David Chapman's just said in his podcast.
Sometimes all you need to do is plot it. All you need is the descriptive statistics. You don't need
the interpretive. I can't remember what it's called. The interpretive statistics to see that
there's something there. And if you're relying on P, then you're mostly doing it wrong. So yes,
the statistics classes did a better job of that. But yeah. And it's like... It seems like the
solution to all of this is metarationality. Except the problem is that basically David Chapman is the
person who is talking about that. It's not taught. It's not even recognised as a thing. We are so deep
into this rationalism, propositional tyranny stuff that like... Yeah, I just don't know what to do. I
don't know where to go next. I feel completely rudderless and lost because I see all these huge
problems. But that's the state of where we're at. It's like we're at the huge... We're barely even
at the beginning of recognising that there are problems. And to make any kind of money in the
world, I have to shut up, close my eyes, don't pay attention to all of those problems, and just
regurgitate the nonsense that is bandied around and then go work for some corporate overlord who
just says, "I have to have that piece of paper and do that method because that's the thing that's
accepted." When it's so obviously fucking wrong. And I want to dive into all of that and why it's
wrong and question things, but that's not what gets paid. That's what gets shut down.
So what do I do? How do I live in a world that's becoming increasingly...
Like, I just don't know what to do. ...corporatised and academiaised in the worst possible ways. And
the alliance between those two things where corporatisation... It's corporatisation like
buying into bad academia. Or maybe not in some ways bad, like in some ways it's probably quite
good academia, just without questioning assumptions. The buying into the religion of progress and,
you know, the technology will fix everything and the AI hype and all of this nonsense.
I just don't know what to do. It feels like all of that is a fucking... Like, I'll make money,
but it is intellectually, morally and spiritually a fucking bankrupt and a dead end. And it's not
what I feel called to do, but it's the thing that will make life "comfortable" in that I'll have a
bunch of fucking money, but I will feel dead inside and I'll know what I'm doing is fucking
pointless and wrong, but I'm just shutting up and doing it so I can publish or perish.
I know this is wrong. I know what I'm doing is probably bullshit, but I have to shut up and
do it, otherwise I don't get anywhere. And the alternative is do the thing that actually matters,
but be horribly uncomfortable. Everybody thinks I'm fucking crazy and, like, I have to go against
the grain so hard. Fuck, I feel so utterly lost when the conditions are so fucking against me,
against all of us. And there's no clear way out. There's people, a whole bunch of people,
noticing the issues and fumbling around, but there's no real... There's no answer.
There's the beginning of people starting to question things. We are so far away from an answer,
or from even starting to think about answers.
I don't... I don't want to be horribly uncomfortable, but regardless of what I do,
I'm going to be uncomfortable. Like, either I do the thing I want to do and I'm poor and
everybody thinks I'm crazy and I'm pushing a fucking boulder uphill my entire life,
or I do the thing... I shut up and swallow the pill and do the thing and make money and be
physically somewhat comfortable, but be intellectually, morally and spiritually dead inside.
I hate everything I'm doing. Thinking about all of this, and, yeah, I was just thinking the other
day about getting into academia and all that kind of stuff. I talked to Alex about it and the prospect
of, you know, thinking about this, putting this in words like this, thinking about it out loud,
listening to David Chapman and this other guy's talk here, it just reminds me of all the, you know,
the pee hacking and all that, as Publish or Perish. I don't want to be part of that.
I just don't know what the... how do I get pay... how do I make a life out of asking questions like
this and exploring these things and not have to fucking go to a corporate job all day every day
and sell my life and my soul to get by? Because I want to spend my life doing this. How about...
like how do I get... nobody's going to pay me to do that because that's like against the...
it's like in academic corporate interest, all corporate industries interest to not pay
to do this. It's awesome. That's what 30 minutes in the other guy references seeing like a state
and he links making things more legible to states to statistics. He talks about how he questions
whether maybe statistics is the form of that, that modernist state capture of things applied
to science, whether statistics is the way that states try to make science more legible. And like
the preponderance, like the focusing on P is like a way to make science more legible to
institutional... to institutions. It's a way to sort papers as to significant or not significant.
And all of this connects to the link between capitalism and propositional tyranny,
and the link between propositional tyranny and where we're at with states.
And that propositional tyranny is baked into the way our states and our institutions work
because it makes them more legible. We need to deal with the nebulosity of things because states
can't... because states operate and institutions operate generally or like well they... actually,
yeah, states and institutions and corporations operate on rationalism. They operate on making
getting rid of the fuzziness of things and focusing and just dealing with the
hard boundaries of things. But then that means in practice, most of people's existence in those
things is interfacing between that and the messiness of reality. And he says that the
alternative to that is what proper old science used to be, which was actually asking, "Does this
make sense?" As David Chapman says, like a succinct summary, the fundamental issue of where science is
at is that it's substituted metrics for actual understanding and everybody just gains the metrics.
